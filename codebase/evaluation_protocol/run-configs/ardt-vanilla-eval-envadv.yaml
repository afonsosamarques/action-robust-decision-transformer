env_type: "halfcheetah"  # halfcheetah, hopper, walker2d
run_type: "pipeline"  # "core", "pipeline", or "test"
hf_project: 'afonsosamarques' # personal project, or ARDT-Project, or ARDT-Internal

trained_model_names: ['ardt-vanilla-d4rl_expert_halfcheetah-1907_1733', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-1907_1752', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-1907_1811', 'ardt-vanilla-d4rl_expert_halfcheetah-1907_2135', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-1907_2249', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-1907_2303', 'ardt-vanilla-d4rl_expert_halfcheetah-2007_0149', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2007_0348', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2007_0353', 'ardt-vanilla-d4rl_expert_halfcheetah-2007_0600', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2007_0850', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2007_0849', 'ardt-vanilla-d4rl_expert_halfcheetah-2007_1016', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2007_1343', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2007_1357', 'ardt-vanilla-d4rl_expert_halfcheetah-2007_1436', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2007_1841', 'ardt-vanilla-d4rl_expert_halfcheetah-2007_1854', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2007_1920', 'ardt-vanilla-d4rl_expert_halfcheetah-2007_2310', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2007_2338', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2107_0020', 'ardt-vanilla-d4rl_expert_halfcheetah-2107_0310', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2107_0432', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2107_0515', 'ardt-vanilla-nrmdp_train_halfcheetah_v4-2107_0928', 'ardt-vanilla-dataset_combo_train_halfcheetah_v1-2107_1026']  # names from models stored on the repo (any readable identifier is ok if stored locally)
trained_model_types: ['ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla', 'ardt-vanilla']  # dt, ardt-simplest, ardt-vanilla, ardt-full, arrl, ppo, trpo, randagent
trained_model_paths: ['hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf', 'hf']  # hf if hf hosted, otherwise actual local path to model from 'codebase' directory down
eval_type: "env_adv"  # no_adv, env_adv, agent_adv
eval_steps: 1000  # 1000 is the default in DT
eval_target_return: 12000  # note this should depend on environment and steps!! 12k is for halfcheetah and 1000 steps for example
eval_iters: 20  # ensure robust evaluation

# only if using an explicit adversary!! i.e. eval_type = "agent_adv"
adv_model_names: []  # names from models stored on the repo
adv_model_types: []  # dt, ardt-simplest, ardt-vanilla, ardt-full, arrl, randagent
adv_model_paths: []  # hf if hf hosted, otherwise actual local path to model from 'action-robust-decision-transformer' directory down
