{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import DecisionTransformerConfig\n",
    "\n",
    "#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./eval-outputs-pipeline\"\n",
    "MODEL_TYPES = ['dt', 'ardt-simplest', 'ardt-vanilla', 'ardt-full']\n",
    "WITH_NO_ADV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_paths = sorted([DIR + \"/\" + r for r in os.listdir(DIR) if os.path.isdir(os.path.join(DIR, r))])\n",
    "results_paths = results_paths[:-2]\n",
    "results_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_results = defaultdict(list)\n",
    "\n",
    "for i, path in enumerate(results_paths):\n",
    "    model_name = path.split(\"/\")[-1][:-10]\n",
    "    model_config = DecisionTransformerConfig.from_pretrained(\"ARDT-Internal/\" + path.split(\"/\")[-1], use_auth_token=True)\n",
    "    done = False\n",
    "    for type in MODEL_TYPES:\n",
    "        if model_name.startswith(type + \"-\"):\n",
    "            done = True\n",
    "            model_type = type\n",
    "            models_to_results['type'].append(model_type)\n",
    "            models_to_results['type'].append(model_type)\n",
    "    if not done: continue\n",
    "    models_to_results['name'].append(model_name)\n",
    "    models_to_results['name'].append(model_name)\n",
    "    models_to_results['number'].append(i)\n",
    "    models_to_results['number'].append(i)\n",
    "    models_to_results['lambda1'].append(model_config.lambda1)\n",
    "    models_to_results['lambda1'].append(model_config.lambda1)\n",
    "    models_to_results['lambda2'].append(model_config.lambda2)\n",
    "    models_to_results['lambda2'].append(model_config.lambda2)\n",
    "    dataset = model_name.split(\"-\")[-1]\n",
    "    models_to_results['dataset'].append(dataset)\n",
    "    models_to_results['dataset'].append(dataset)\n",
    "    model_id = f\"{model_type} | {dataset} | l1 = {model_config.lambda1} | l2 = {model_config.lambda2}\"\n",
    "    models_to_results['id'].append(model_id)\n",
    "    models_to_results['id'].append(model_id)\n",
    "    models_to_results['id_no_space'].append(model_id)\n",
    "    models_to_results['id_no_space'].append(model_id)\n",
    "    model_id_short = f\"{model_type} | {dataset}\"\n",
    "    models_to_results['id_short'].append(model_id_short)\n",
    "    models_to_results['id_short'].append(model_id_short)\n",
    "\n",
    "    model_returns = []\n",
    "    model_returns_means = []\n",
    "    model_returns_mins = []\n",
    "    for subpath in os.listdir(path):\n",
    "        if not WITH_NO_ADV and subpath.startswith(\"no-adv\"): continue\n",
    "        with open(path + \"/\" + subpath, \"rb\") as f:\n",
    "            model_adv_returns = json.load(f)['ep_return']\n",
    "        model_returns.append(model_adv_returns)\n",
    "        model_returns_means.append(np.mean(model_adv_returns))\n",
    "        model_returns_mins.append(np.min(model_adv_returns))\n",
    "\n",
    "    models_to_results['returns'].append(int(np.mean(model_returns_means)))\n",
    "    models_to_results['returns'].append(int(np.min(model_returns_mins)))\n",
    "    models_to_results['return_types'].append(\"mean_returns\")\n",
    "    models_to_results['return_types'].append(\"min_returns\")\n",
    "\n",
    "def get_length(length, max_length, part, nparts=4):\n",
    "    multiple = 0.65 if (part % nparts) == 0 else (0.90 if (part % nparts) == 1 else 0)\n",
    "    return max_length if length == max_length else max_length + int((max_length - length) * multiple)\n",
    "\n",
    "parts = [s.split(\"|\") for s in models_to_results['id']]\n",
    "counts = [i for i in range(len(parts[0]))]\n",
    "max_lengths = [max(len(part[i]) for part in parts) for i in range(len(parts[0]))]\n",
    "aligned_strings = [\"|\".join(part.ljust(get_length(len(part), max_length, ct)) for part, max_length, ct in zip(parts[i], max_lengths, counts)) for i in range(len(parts))]\n",
    "models_to_results['id'] = aligned_strings\n",
    "models_to_results['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_by_dataset = False  # FIXME\n",
    "datasets = sorted(list(set([m for m in models_to_results['dataset']])))\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_by_dataset:\n",
    "    dataset_idx = -1  # FIXME\n",
    "    dataset = datasets[dataset_idx]\n",
    "    models_to_results = {k: [v for i, v in enumerate(models_to_results[k]) if models_to_results['dataset'][i] == dataset] for k in models_to_results.keys()}\n",
    "models_to_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "df = pd.DataFrame.from_dict(models_to_results)\n",
    "sns.barplot(data=df, x=\"return_types\", y=\"returns\", hue=\"id\")\n",
    "plt.legend(fontsize='small', loc='upper right', bbox_to_anchor=(1, 1))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_MIN = True\n",
    "models_to_results_two = defaultdict(list)\n",
    "\n",
    "for i, path in enumerate(results_paths):\n",
    "    model_name = path.split(\"/\")[-1][:-10]\n",
    "    model_config = DecisionTransformerConfig.from_pretrained(\"ARDT-Internal/\" + path.split(\"/\")[-1], use_auth_token=True)\n",
    "    done = False\n",
    "    for type in MODEL_TYPES:\n",
    "        if model_name.startswith(type + \"-\"):\n",
    "            done = True\n",
    "            model_type = type\n",
    "            models_to_results_two['type'].append(model_type)\n",
    "            models_to_results_two['type'].append(model_type)\n",
    "    if not done: continue\n",
    "    models_to_results_two['name'].append(model_name)\n",
    "    models_to_results_two['name'].append(model_name)\n",
    "    models_to_results_two['number'].append(i)\n",
    "    models_to_results_two['number'].append(i)\n",
    "    models_to_results_two['lambda1'].append(model_config.lambda1)\n",
    "    models_to_results_two['lambda1'].append(model_config.lambda1)\n",
    "    models_to_results_two['lambda2'].append(model_config.lambda2)\n",
    "    models_to_results_two['lambda2'].append(model_config.lambda2)\n",
    "    dataset = model_name.split(\"-\")[-1]\n",
    "    models_to_results_two['dataset'].append(dataset)\n",
    "    models_to_results_two['dataset'].append(dataset)\n",
    "    model_id = f\"{model_type} | {dataset} | l1 = {model_config.lambda1} | l2 = {model_config.lambda2}\"\n",
    "    models_to_results_two['id'].append(model_id)\n",
    "    models_to_results_two['id'].append(model_id)\n",
    "    models_to_results_two['id_no_space'].append(model_id)\n",
    "    models_to_results_two['id_no_space'].append(model_id)\n",
    "    model_id_short = f\"{model_type} | {dataset}\"\n",
    "    models_to_results_two['id_short'].append(model_id_short)\n",
    "    models_to_results_two['id_short'].append(model_id_short)\n",
    "\n",
    "    model_returns = []\n",
    "    model_returns_means = []\n",
    "    model_returns_mins = []\n",
    "    for subpath in os.listdir(path):\n",
    "        if subpath.startswith(\"no-adv\"): continue\n",
    "        with open(path + \"/\" + subpath, \"rb\") as f:\n",
    "            model_adv_returns = json.load(f)['ep_return']\n",
    "        model_returns.append(model_adv_returns)\n",
    "        model_returns_means.append(np.mean(model_adv_returns))\n",
    "        model_returns_mins.append(np.min(model_adv_returns))\n",
    "\n",
    "    if not IS_MIN:\n",
    "        models_to_results_two['returns'].append(int(np.mean(model_returns_means)))\n",
    "        models_to_results_two['return_types'].append(\"mean_returns_adv\")\n",
    "    else:\n",
    "        models_to_results_two['returns'].append(int(np.min(model_returns_means)))\n",
    "        models_to_results_two['return_types'].append(\"min_returns_adv\")\n",
    "\n",
    "    model_returns = []\n",
    "    model_returns_means = []\n",
    "    model_returns_mins = []\n",
    "    for subpath in os.listdir(path):\n",
    "        if not subpath.startswith(\"no-adv\"): continue\n",
    "        with open(path + \"/\" + subpath, \"rb\") as f:\n",
    "            model_noadv_returns = json.load(f)['ep_return']\n",
    "        model_returns.append(model_noadv_returns)\n",
    "        model_returns_means.append(np.mean(model_noadv_returns))\n",
    "        model_returns_mins.append(np.min(model_noadv_returns))\n",
    "\n",
    "    if not IS_MIN:\n",
    "        models_to_results_two['returns'].append(int(np.mean(model_returns_means)))\n",
    "        models_to_results_two['return_types'].append(\"mean_returns_noadv\")\n",
    "    else:\n",
    "        models_to_results_two['returns'].append(int(np.min(model_returns_means)))\n",
    "        models_to_results_two['return_types'].append(\"min_returns_noadv\")\n",
    "\n",
    "def get_length(length, max_length, part, nparts=4):\n",
    "    multiple = 0.65 if (part % nparts) == 0 else (0.90 if (part % nparts) == 1 else 0)\n",
    "    return max_length if length == max_length else max_length + int((max_length - length) * multiple)\n",
    "\n",
    "parts = [s.split(\"|\") for s in models_to_results_two['id']]\n",
    "counts = [i for i in range(len(parts[0]))]\n",
    "max_lengths = [max(len(part[i]) for part in parts) for i in range(len(parts[0]))]\n",
    "aligned_strings = [\"|\".join(part.ljust(get_length(len(part), max_length, ct)) for part, max_length, ct in zip(parts[i], max_lengths, counts)) for i in range(len(parts))]\n",
    "models_to_results_two['id'] = aligned_strings\n",
    "models_to_results_two['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_by_dataset = False  # FIXME\n",
    "datasets = sorted(list(set([m for m in models_to_results_two['dataset']])))\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filter_by_dataset:\n",
    "    dataset_idx = -1  # FIXME\n",
    "    dataset = datasets[dataset_idx]\n",
    "    models_to_results = {k: [v for i, v in enumerate(models_to_results_two[k]) if models_to_results_two['dataset'][i] == dataset] for k in models_to_results_two.keys()}\n",
    "models_to_results_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "df = pd.DataFrame.from_dict(models_to_results_two)\n",
    "sns.barplot(data=df, x=\"id\", y=\"returns\", hue=\"return_types\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(fontsize='small', loc='upper right', bbox_to_anchor=(1, 1))\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp-adt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
