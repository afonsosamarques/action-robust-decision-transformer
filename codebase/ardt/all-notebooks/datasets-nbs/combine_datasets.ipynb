{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "dir = os.path.abspath('')\n",
    "while not dir.endswith('ardt'): dir = os.path.dirname(dir)\n",
    "if not dir in sys.path: sys.path.append(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from huggingface_hub import login\n",
    "\n",
    "from utils.helpers import find_root_dir\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARDT_DIR = find_root_dir()\n",
    "VERSION_OF_COMBO = \"v1\"  # PLEASE CHANGE TO AVOID OVERRIDING!!!!!\n",
    "ENVIRONMENT_NAME = \"halfcheetah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 1000\n",
    "episode_len = 1000\n",
    "total_steps = total_episodes * episode_len  # ideally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_names = [\"ppo_eval_halfcheetah\", \"arrl_nrmdp_train_halfcheetah\"]\n",
    "# weight_combs = []\n",
    "# for i in [0.0, 0.1, 0.35, 0.65, 0.9, 1.0]:\n",
    "#     weight_combs.append([round(1.0-i, 2), i])\n",
    "\n",
    "# weight_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"ppo_test_halfcheetah_v3\", \"arrl_nrmdp_train_halfcheetah\", \"ppo_randadv_test_halfcheetah_v3_filtered\"]\n",
    "weight_combs = [\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 0.5, 0.5],\n",
    "    [0.5, 0.25, 0.25],\n",
    "    [0.5, 0.5, 0],\n",
    "    [1/3, 1/3, 1/3],\n",
    "    [1/3, 2/3, 0],\n",
    "    [0.1, 0.45, 0.45],\n",
    "    [0.1, 0.9, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sum(ds):\n",
    "    return {'returns': sum(ds['rewards'])}\n",
    "\n",
    "for i, weights in enumerate(weight_combs):\n",
    "    assert np.sum(weights) == 1, f\"Weights {weights} need to sum to 1.\"\n",
    "    episodes_per_ds = [int(w * total_episodes) for w in weights]\n",
    "    j = 0\n",
    "    while(sum(episodes_per_ds) != 1000):\n",
    "        episodes_per_ds[j] += 1\n",
    "        j += 1\n",
    "        if j == len(dataset_names):\n",
    "            j = 0\n",
    "    \n",
    "    super_dataset = None\n",
    "    for dataset_name, eps in zip(dataset_names, episodes_per_ds):\n",
    "        if eps == 0:\n",
    "            continue\n",
    "        # load dataset\n",
    "        ds = load_from_disk(f\"{ARDT_DIR}/datasets/{dataset_name}\")\n",
    "        ds = ds.map(compute_sum)\n",
    "        # select last episodes_per_ds episodes\n",
    "        len_ds = len(ds['observations'])\n",
    "        ds = ds.select(range(len_ds-eps, len_ds))\n",
    "        # # visualise selection of dataset\n",
    "        # returns = (np.array(ds['rewards'])).sum(axis=1)\n",
    "        # sns.displot(returns, kind=\"kde\", bw_adjust=0.5);\n",
    "        # add to super dataset\n",
    "        if super_dataset is None:\n",
    "            super_dataset = ds\n",
    "        else:\n",
    "            ds = ds.cast(super_dataset.features)\n",
    "            super_dataset = concatenate_datasets([super_dataset, ds])\n",
    "    # visualise combined dataset\n",
    "    ds_to_vis = super_dataset.map(compute_sum)\n",
    "    print(f\"Datasets: {dataset_names} \\n Weights: {weights}\")\n",
    "    sns.displot(ds_to_vis['returns'], kind=\"kde\", bw_adjust=0.5);\n",
    "    # save\n",
    "    super_dataset.save_to_disk(f'{ARDT_DIR}/datasets-to-push/dataset_combo_train_{ENVIRONMENT_NAME}_v{i+1}_new')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp-adt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
