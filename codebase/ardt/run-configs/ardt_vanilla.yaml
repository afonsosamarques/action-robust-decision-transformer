environment_config:
  env_type: "halfcheetah"  # halfcheetah, hopper, walker2d
  max_ep_len: 1000  # limit episode length for offline dataset
  returns_scale: 1000  # scale returns, 1000 to match original DT implementation

dataset_config:
  is_local: [true]  # true, false, whether it is stored locally or up on HF
  online_policy_names: ["dataset_combo"]  # d4rl, rarl, arrl, arrl_sgld, dataset_combo, etc.
  dataset_types: ["train"]  # train, test, expert
  dataset_versions: ["v1"]  # fill only if there is any type of versioning to the dataset being considered

model_config:
  agent_type: "ardt-vanilla"  # dt, dt-multipart, ardt-vanilla, ardt-multipart
  context_size: [20]  # size of context window (we do +1 for multipart)

training_config:
  train_steps: 4  # 6 => 10**6
  warmup_steps: [3]  # 4 => 10**4
  train_batch_size: [64]  # 32/64
  learning_rate: [-4]  # these are for different parameter combinations to try!! e.g. -4 => 10**-4 | original: -4
  weight_decay: [-4]  # these are for different parameter combinations to try!! e.g. -4 => 10**-4 | original: -4
  max_grad_norm: [0.25]  # these are for different parameter combinations to try!! | original: 0.25
  seeds: [13]  # to train multiple models with different initialisations

admin_config:
  wandb_project: "afonsosamarques"  # project name
  hf_project: "afonsosamarques"  # project name
  run_type: "core"  # "core", "pipeline", or "test"
